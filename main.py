# -*- coding: utf-8 -*-
"""FINAL CODE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gZn6EFyCn7uX2BDSaMrWCT8e8HsD2i_I
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn.datasets import fetch_openml

# Load the Diabetes dataset
data = fetch_openml(name="diabetes", version=1, as_frame=True)
X = data.data
y = data.target.map({"tested_negative": 0, "tested_positive": 1})

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize and Train the Non-Ethical Model
model_non_ethical = RandomForestClassifier(random_state=42)
model_non_ethical.fit(X_train, y_train)

# Make Predictions
y_pred_non_ethical = model_non_ethical.predict(X_test)

# Evaluate the Non-Ethical Model
accuracy_non_ethical = accuracy_score(y_test, y_pred_non_ethical)
print("Non-Ethical Model Accuracy: {:.2f}%".format(accuracy_non_ethical * 100))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_non_ethical))
print("\nClassification Report:\n", classification_report(y_test, y_pred_non_ethical))

# Plot Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_non_ethical), annot=True, fmt='d', cmap='Blues')
plt.title("Non-Ethical Model Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Corrected Ethical AI Code
from imblearn.over_sampling import SMOTE

# Bias Analysis: Checking for Data Imbalance
class_counts = y.value_counts()
print("Class Distribution Before Balancing:\n", class_counts)

# Apply SMOTE if dataset is imbalanced
if abs(class_counts[0] - class_counts[1]) > 50:
    smote = SMOTE(random_state=42)
    X_train, y_train = smote.fit_resample(X_train, y_train)
    print("Applied SMOTE to balance the dataset.")

# Initialize and Train the Ethical Model
model_ethical = RandomForestClassifier(random_state=42)
model_ethical.fit(X_train, y_train)

# Make Predictions
y_pred_ethical = model_ethical.predict(X_test)

# Evaluate the Ethical Model
accuracy_ethical = accuracy_score(y_test, y_pred_ethical)
print("Ethical Model Accuracy: {:.2f}%".format(accuracy_ethical * 100))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_ethical))
print("\nClassification Report:\n", classification_report(y_test, y_pred_ethical))

# Plot Confusion Matrix for Ethical Model
sns.heatmap(confusion_matrix(y_test, y_pred_ethical), annot=True, fmt='d', cmap='Greens')
plt.title("Ethical Model Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC Curve
fpr_non_ethical, tpr_non_ethical, _ = roc_curve(y_test, model_non_ethical.predict_proba(X_test)[:,1])
fpr_ethical, tpr_ethical, _ = roc_curve(y_test, model_ethical.predict_proba(X_test)[:,1])

plt.plot(fpr_non_ethical, tpr_non_ethical, linestyle='--', label='Non-Ethical Model')
plt.plot(fpr_ethical, tpr_ethical, linestyle='-', label='Ethical Model')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# Feature Importance Visualization
feature_importances = model_ethical.feature_importances_
features = X.columns

plt.figure(figsize=(10, 5))
sns.barplot(x=features, y=feature_importances)
plt.xticks(rotation=90)
plt.title("Feature Importance in Ethical Model")
plt.show()